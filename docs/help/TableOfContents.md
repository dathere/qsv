# qsv Command Help

> Auto-generated from qsv command USAGE text. See [README](../../README.md) for full documentation.

| Command | Description |
| --- | --- |
| [apply](apply.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="expensive operations are memoized with available inter-session Redis/Disk caching for fetch commands.">ğŸ§ </abbr><abbr title="command uses Natural Language Processing or Generative AI.">ğŸ¤–</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Apply series of string, date, math & currency transformations to given CSV column/s. It also has some basic [NLP](https://en.wikipedia.org/wiki/Natural_language_processing) functions ([similarity](https://crates.io/crates/strsim), [sentiment analysis](https://crates.io/crates/vader_sentiment), [profanity](https://docs.rs/censor/latest/censor/), [eudex](https://github.com/ticki/eudex#eudex-a-blazingly-fast-phonetic-reductionhashing-algorithm), [language](https://crates.io/crates/whatlang) & [name gender](https://github.com/Raduc4/gender_guesser?tab=readme-ov-file#gender-guesser)) detection. |
| [applydp](applydp.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> ![CKAN](../images/ckan.png "has CKAN-aware integration options.") | applydp is a slimmed-down version of `apply` with only [Datapusher+](https://github.com/dathere/datapusher-plus) relevant subcommands/operations (`qsvdp` binary variant only). |
| [behead](behead.md) | Drop headers from a CSV. |
| [cat](cat.md)<br><abbr title="Extended input support.">ğŸ—„ï¸</abbr> | Concatenate CSV files by row or by column. |
| [clipboard](clipboard.md)<br><abbr title="part of the User Interface (UI) feature group">ğŸ–¥ï¸</abbr> | Provide input from the clipboard or save output to the clipboard. |
| [color](color.md)<br><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr><abbr title="part of the User Interface (UI) feature group">ğŸ–¥ï¸</abbr> | Outputs tabular data as a pretty, colorized table that always fits into the terminal. Apart from CSV and its dialects, Arrow, Avro/IPC, Parquet, JSON array & JSONL formats are supported with the "polars" feature. |
| [count](count.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr> | Count the rows and optionally compile record width statistics of a CSV file. (11.87 seconds for a 15gb, 27m row NYC 311 dataset without an index. Instantaneous with an index.) If the `polars` feature is enabled, uses Polars' multithreaded, mem-mapped CSV reader for fast counts even without an index |
| [datefmt](datefmt.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Formats recognized date fields ([19 formats recognized](https://docs.rs/qsv-dateparser/latest/qsv_dateparser/#accepted-date-formats)) to a specified date format using [strftime date format specifiers](https://docs.rs/chrono/latest/chrono/format/strftime/). |
| [dedup](dedup.md)<br><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Remove duplicate rows (See also `extdedup`, `extsort`, `sort` & `sortcheck` commands). |
| [describegpt](describegpt.md)<br><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="command uses Natural Language Processing or Generative AI.">ğŸ¤–</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr><abbr title="Limited Extended input support.">ğŸ—ƒï¸</abbr><abbr title="has lookup table support, enabling runtime &quot;lookups&quot; against local or remote reference CSVs.">ğŸ“š</abbr><abbr title="uses Mini Jinja template engine.">â›©ï¸</abbr> ![CKAN](../images/ckan.png "has CKAN-aware integration options.") | Infer a ["neuro-symbolic"](https://en.wikipedia.org/wiki/Neuro-symbolic_AI) Data Dictionary, Description & Tags or ask questions about a CSV with a [configurable, Mini Jinja prompt file](../../resources/describegpt_defaults.toml), using any [OpenAI API](https://platform.openai.com/docs/introduction)-compatible LLM, including local LLMs via [Ollama](https://ollama.com), [Jan](https://jan.ai) & [LM Studio](https://lmstudio.ai/). (e.g. [Markdown](../describegpt/nyc311-describegpt.md), [JSON](../describegpt/nyc311-describegpt.json), [TOON](../describegpt/nyc311-describegpt.toon), [Everything](../describegpt/nyc311-describegpt-everything.md), [Spanish](../describegpt/nyc311-describegpt-spanish.md), [Mandarin](../describegpt/nyc311-describegpt-mandarin.md), [Controlled Tags](../describegpt/nyc311-describegpt-tagvocab.md); [--prompt "What are the top 10 complaint types by community board & borough by year?"](../describegpt/nyc311-describegpt-prompt.md) - [deterministic, hallucination-free SQL RAG result](../describegpt/nyc311-describegpt-prompt.csv); [iterative, session-based SQL RAG refinement](../describegpt/allegheny_discussion3.md) - [refined SQL RAG result](../describegpt/mostexpensive6.csv)) |
| [diff](diff.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr> | Find the difference between two CSVs with ludicrous speed! e.g. _compare two CSVs with 1M rows x 9 columns in under 600ms!_ |
| [edit](edit.md) | Replace the value of a cell specified by its row and column. |
| [enum](enum.md)<br><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Add a new column enumerating rows by adding a column of incremental or uuid identifiers. Can also be used to copy a column or fill a new column with a constant value. |
| [excel](excel.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr> | Exports a specified Excel/ODS sheet to a CSV file. |
| [exclude](exclude.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Removes a set of CSV data from another set based on the specified columns. |
| [explode](explode.md)<br><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Explode rows into multiple ones by splitting a column value based on the given separator. |
| [extdedup](extdedup.md)<br><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Remove duplicate rows from an arbitrarily large CSV/text file using a memory-mapped, [on-disk hash table](https://crates.io/crates/odht). Unlike the `dedup` command, this command does not load the entire file into memory nor does it sort the deduped file. |
| [extsort](extsort.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Sort an arbitrarily large CSV/text file using a multithreaded [external merge sort](https://en.wikipedia.org/wiki/External_sorting) algorithm. |
| [fetch](fetch.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="expensive operations are memoized with available inter-session Redis/Disk caching for fetch commands.">ğŸ§ </abbr><abbr title="has web-aware options.">ğŸŒ</abbr> | Send/Fetch data to/from web services for every row using **HTTP Get**. Comes with [HTTP/2](https://http2-explained.haxx.se/en/part1) [adaptive flow control](https://medium.com/coderscorner/http-2-flow-control-77e54f7fd518), [jaq](https://github.com/01mf02/jaq?tab=readme-ov-file#jaq) JSON query language support, dynamic throttling ([RateLimit](https://www.ietf.org/archive/id/draft-ietf-httpapi-ratelimit-headers-06.html)) & caching with available persistent caching using [Redis](https://redis.io/) or a disk-cache. |
| [fetchpost](fetchpost.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="expensive operations are memoized with available inter-session Redis/Disk caching for fetch commands.">ğŸ§ </abbr><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="uses Mini Jinja template engine.">â›©ï¸</abbr> | Similar to `fetch`, but uses **HTTP Post** ([HTTP GET vs POST methods](https://www.geeksforgeeks.org/difference-between-http-get-and-post-methods/)). Supports HTML form (application/x-www-form-urlencoded), JSON (application/json) and custom content types - with the ability to render payloads using CSV data using the [Mini Jinja](https://docs.rs/minijinja/latest/minijinja/) template engine. |
| [fill](fill.md)<br><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Fill empty values. |
| [fixlengths](fixlengths.md) | Force a CSV to have same-length records by either padding or truncating them. |
| [flatten](flatten.md) | A flattened view of CSV records. Useful for viewing one record at a time. e.g. `qsv slice -i 5 data.csv \| qsv flatten`. |
| [fmt](fmt.md) | Reformat a CSV with different delimiters, record terminators or quoting rules. (Supports ASCII delimited data.) |
| [foreach](foreach.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr> | Execute a shell command once per record in a given CSV file. |
| [frequency](frequency.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="uses additional memory proportional to the cardinality of the columns in the CSV.">ğŸ˜£</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr>![Luau](../images/luau.png "uses Luau 0.708 as an embedded scripting DSL.") | Build [frequency distribution tables](https://en.wikipedia.org/wiki/Frequency_(statistics)) of each column. Uses multithreading to go faster if an index is present (Examples: [CSV](../../scripts/nyc311-1m.freqs.csv) [JSON](../../scripts/nyc311-1m.freqs.json) [TOON](../../scripts/nyc311-1m.freqs.toon)). |
| [geocode](geocode.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="expensive operations are memoized with available inter-session Redis/Disk caching for fetch commands.">ğŸ§ </abbr><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr><abbr title="has geospatial capabilities.">ğŸŒ</abbr> | Geocodes a location against an updatable local copy of the [Geonames](https://www.geonames.org/) cities & the [Maxmind GeoLite2](https://www.maxmind.com/en/geolite-free-ip-geolocation-data) databases. With caching and multi-threading, it geocodes up to 360,000 records/sec! |
| [geoconvert](geoconvert.md)<br><abbr title="has geospatial capabilities.">ğŸŒ</abbr> | Convert between various spatial formats and CSV/SVG including GeoJSON, SHP, and more. |
| [headers](headers.md)<br><abbr title="Extended input support.">ğŸ—„ï¸</abbr> | Show the headers of a CSV. Or show the intersection of all headers between many CSV files. |
| [index](index.md) | Create an index for a CSV. This is very quick (even the 15gb, 28m row NYC 311 dataset takes all of 14 seconds to index) & provides constant time indexing/random access into the CSV. With an index, `count`, `sample` & `slice` work instantaneously; random access mode is enabled in `luau`; and multithreading is enabled for the `frequency`, `split`, `stats`, `schema` & `tojsonl` commands. |
| [input](input.md) | Read CSV data with special commenting, quoting, trimming, line-skipping & non-UTF8 encoding handling rules. Typically used to "normalize" a CSV for further processing with other qsv commands. |
| [join](join.md)<br><abbr title="uses additional memory proportional to the cardinality of the columns in the CSV.">ğŸ˜£</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Inner, outer, right, cross, anti & semi joins. Automatically creates a simple, in-memory hash index to make it fast. |
| [joinp](joinp.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr> | Inner, outer, right, cross, anti, semi, non-equi & asof joins using the [Pola.rs](https://www.pola.rs) engine. Unlike the `join` command, `joinp` can process files larger than RAM, is multithreaded, has join key validation, a maintain row order option, pre and post-join filtering, join keys unicode normalization, supports "special" [non-equi joins](https://docs.pola.rs/user-guide/transformations/joins/#non-equi-joins) and [asof joins](https://docs.pola.rs/user-guide/transformations/joins/#asof-join) (which is [particularly useful for time series data](https://github.com/dathere/qsv/blob/30cc920d0812a854fcbfedc5db81788a0600c92b/tests/test_joinp.rs#L509-L983)) & its output columns can be coalesced. |
| [json](json.md)<br><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Convert JSON array to CSV. |
| [jsonl](jsonl.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr> | Convert newline-delimited JSON ([JSONL](https://jsonlines.org/)/[NDJSON](http://ndjson.org/)) to CSV. See `tojsonl` command to convert CSV to JSONL. |
| [lens](lens.md)<br><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr><abbr title="part of the User Interface (UI) feature group">ğŸ–¥ï¸</abbr> | Interactively view, search & filter tabular data files using the [csvlens](https://github.com/YS-L/csvlens#csvlens) engine. Apart from CSV and its dialects, Arrow, Avro/IPC, Parquet, JSON array & JSONL formats are supported with the "polars" feature. |
| [luau](luau.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has lookup table support, enabling runtime &quot;lookups&quot; against local or remote reference CSVs.">ğŸ“š</abbr> ![CKAN](../images/ckan.png "has CKAN-aware integration options.") | Create multiple new computed columns, filter rows, compute aggregations and build complex data pipelines by executing a [Luau](https://luau-lang.org) [0.708](https://github.com/Roblox/luau/releases/tag/0.708) expression/script for every row of a CSV file ([sequential mode](https://github.com/dathere/qsv/blob/bb72c4ef369d192d85d8b7cc6e972c1b7df77635/tests/test_luau.rs#L254-L298)), or using [random access](https://www.webopedia.com/definitions/random-access/) with an index ([random access mode](https://github.com/dathere/qsv/blob/bb72c4ef369d192d85d8b7cc6e972c1b7df77635/tests/test_luau.rs#L367-L415)). Can process a single Luau expression or [full-fledged data-wrangling scripts using lookup tables](https://github.com/dathere/qsv-lookup-tables#example) with discrete BEGIN, MAIN and END sections. It is not just another qsv command, it is qsv's [Domain-specific Language](https://en.wikipedia.org/wiki/Domain-specific_language) (DSL) with [numerous qsv-specific helper functions](https://github.com/dathere/qsv/blob/113eee17b97882dc368b2e65fec52b86df09f78b/src/cmd/luau.rs#L1356-L2290) to build production data pipelines. |
| [moarstats](moarstats.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr> | Add dozens of additional statistics, including extended outlier, robust & bivariate statistics to an existing stats CSV file. ([example](../moarstats/NYC_311_SR_2010-2020-sample-1M.stats.csv)). |
| [partition](partition.md)<br><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Partition a CSV based on a column value. |
| [pivotp](pivotp.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr> | Pivot CSV data. Features "smart" aggregation auto-selection based on data type & stats. |
| [pragmastat](pragmastat.md)<br><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr> | Compute pragmatic statistics using the [Pragmastat](https://pragmastat.dev/) library. |
| [pro](pro.md) | Interact with the [qsv pro](https://qsvpro.dathere.com) API. |
| [prompt](prompt.md)<br><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr><abbr title="part of the User Interface (UI) feature group">ğŸ–¥ï¸</abbr> | Open a file dialog to either pick a file as input or save output to a file. |
| [pseudo](pseudo.md)<br><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | [Pseudonymise](https://en.wikipedia.org/wiki/Pseudonymization) the value of the given column by replacing them with an incremental identifier. |
| [py](py.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr> | Create a new computed column or filter rows by evaluating a Python expression on every row of a CSV file. Python's [f-strings](https://www.freecodecamp.org/news/python-f-strings-tutorial-how-to-use-f-strings-for-string-formatting/) is particularly useful for extended formatting, [with the ability to evaluate Python expressions as well](https://github.com/dathere/qsv/blob/4cd00dca88addf0d287247fa27d40563b6d46985/src/cmd/python.rs#L23-L31). [Requires Python 3.8 or greater](https://github.com/dathere/qsv/blob/master/docs/INTERPRETERS.md#building-qsv-with-python-feature). |
| [rename](rename.md) | Rename the columns of a CSV efficiently. |
| [replace](replace.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr> | Replace CSV data using a regex. Applies the regex to each field individually. |
| [reverse](reverse.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr> | Reverse order of rows in a CSV. Unlike the `sort --reverse` command, it preserves the order of rows with the same key. If an index is present, it works with constant memory. Otherwise, it will load all the data into memory. |
| [safenames](safenames.md)<br>![CKAN](../images/ckan.png "has CKAN-aware integration options.") | Modify headers of a CSV to only have ["safe" names](../../src/cmd/safenames.rs#L5-L14) - guaranteed "database-ready"/"CKAN-ready" names. |
| [sample](sample.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr> | Randomly draw rows (with optional seed) from a CSV using seven different sampling methods - [reservoir](https://en.wikipedia.org/wiki/Reservoir_sampling) (default), [indexed](https://en.wikipedia.org/wiki/Random_access), [bernoulli](https://en.wikipedia.org/wiki/Bernoulli_sampling), [systematic](https://en.wikipedia.org/wiki/Systematic_sampling), [stratified](https://en.wikipedia.org/wiki/Stratified_sampling), [weighted](https://doi.org/10.1016/j.ipl.2005.11.003) & [cluster sampling](https://en.wikipedia.org/wiki/Cluster_sampling). Supports sampling from CSVs on remote URLs. |
| [schema](schema.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="uses additional memory proportional to the cardinality of the columns in the CSV.">ğŸ˜£</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr> | Infer either a [JSON Schema Validation Draft 2020-12](https://json-schema.org/draft/2020-12/json-schema-validation) ([Example](https://github.com/dathere/qsv/blob/master/resources/test/311_Service_Requests_from_2010_to_Present-2022-03-04.csv.schema.json)) or [Polars Schema](https://docs.pola.rs/user-guide/lazy/schemas/) ([Example](https://github.com/dathere/qsv/blob/master/resources/test/NYC_311_SR_2010-2020-sample-1M.pschema.json)) from CSV data. In JSON Schema Validation mode, it produces a `.schema.json` file replete with inferred data type & domain/range validation rules derived from [`stats`](../../README.md#stats_deeplink). Uses multithreading to go faster if an index is present. See [`validate`](../../README.md#validate_deeplink) command to use the generated JSON Schema to validate if similar CSVs comply with the schema. With the `--polars` option, it produces a `.pschema.json` file that all polars commands (`sqlp`, `joinp` & `pivotp`) use to determine the data type of each column & to optimize performance. Both schemas are editable and can be fine-tuned. For JSON Schema, to refine the inferred validation rules. For Polars Schema, to change the inferred Polars data types. |
| [search](search.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Run a regex over a CSV. Applies the regex to selected fields & shows only matching rows. |
| [searchset](searchset.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | _Run multiple regexes over a CSV in a single pass._ Applies the regexes to each field individually & shows only matching rows. |
| [select](select.md)<br><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Select, re-order, reverse, duplicate or drop columns. |
| [slice](slice.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="Limited Extended input support.">ğŸ—ƒï¸</abbr> | Slice rows from any part of a CSV. When an index is present, this only has to parse the rows in the slice (instead of all rows leading up to the start of the slice). |
| [snappy](snappy.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="has web-aware options.">ğŸŒ</abbr> | Does streaming compression/decompression of the input using Google's [Snappy](https://github.com/google/snappy/blob/main/docs/README.md) framing format ([more info](../../README.md#automatic-compressiondecompression)). |
| [sniff](sniff.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="command uses Natural Language Processing or Generative AI.">ğŸ¤–</abbr> ![CKAN](../images/ckan.png "has CKAN-aware integration options.") | Quickly sniff & infer CSV metadata (delimiter, header row, preamble rows, quote character, flexible, is_utf8, average record length, number of records, content length & estimated number of records if sniffing a CSV on a URL, number of fields, field names & data types). It is also a general mime type detector. |
| [sort](sort.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Sorts CSV data in [lexicographical](https://en.wikipedia.org/wiki/Lexicographic_order), [natural](https://en.wikipedia.org/wiki/Natural_sort_order), numerical, reverse, unique or random (with optional seed) order (Also see `extsort` & `sortcheck` commands). |
| [sortcheck](sortcheck.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Check if a CSV is sorted. With the --json options, also retrieve record count, sort breaks & duplicate count. |
| [split](split.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr> | Split one CSV file into many CSV files. It can split by number of rows, number of chunks or file size. Uses multithreading to go faster if an index is present when splitting by rows or chunks. |
| [sqlp](sqlp.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="command powered/accelerated by  vectorized query engine.">ğŸ»â€â„ï¸</abbr><abbr title="Extended input support.">ğŸ—„ï¸</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr> | Run [Polars](https://pola.rs) SQL (a PostgreSQL dialect) queries against several CSVs, Parquet, JSONL and Arrow files - converting queries to blazing-fast Polars [LazyFrame](https://docs.pola.rs/user-guide/lazy/) expressions, processing larger than memory CSV files. Query results can be saved in CSV, JSON, JSONL, Parquet, Apache Arrow IPC and Apache Avro formats. |
| [stats](stats.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr><abbr title="multithreaded and/or faster when an index (ğŸ“‡) is available.">ğŸï¸</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr> | Compute [summary statistics](https://en.wikipedia.org/wiki/Summary_statistics) (sum, min/max/range, sort order/sortiness, min/max/sum/avg length, mean, standard error of the mean (SEM), geometric/harmonic means, stddev, variance, Coefficient of Variation (CV), nullcount, max precision, sparsity, quartiles, Interquartile Range (IQR), lower/upper fences, skewness, median, mode/s, antimode/s, cardinality & uniqueness ratio) & make GUARANTEED data type inferences (Null, String, Float, Integer, Date, DateTime, Boolean) for each column in a CSV ([Example](https://github.com/dathere/qsv/blob/master/scripts/NYC_311_SR_2010-2020-sample-1M.stats.csv) - [more info](https://github.com/dathere/qsv/wiki/Supplemental#stats-command-output-explanation)). Uses multithreading to go faster if an index is present (with an index, can compile "streaming" stats on NYC's 311 data (15gb, 28m rows) in less than 7.3 seconds!). |
| [table](table.md)<br><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr> | Align output of a CSV using [elastic tabstops](https://github.com/BurntSushi/tabwriter) for viewing; or to create an "aligned TSV" file or Fixed Width Format file. To interactively view a CSV, use the `lens` command. |
| [template](template.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="has lookup table support, enabling runtime &quot;lookups&quot; against local or remote reference CSVs.">ğŸ“š</abbr><abbr title="uses Mini Jinja template engine.">â›©ï¸</abbr>![CKAN](../images/ckan.png "has CKAN-aware integration options.") | Renders a template using CSV data with the [Mini Jinja](https://docs.rs/minijinja/latest/minijinja/) template engine ([Example](https://github.com/dathere/qsv/blob/4645ec07b5befe3b0c0e49bf0f547315d0d7514b/src/cmd/template.rs#L18-L44)). |
| [to](to.md)<br><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="Extended input support.">ğŸ—„ï¸</abbr> | Convert CSV files to [PostgreSQL](https://www.postgresql.org), [SQLite](https://www.sqlite.org/index.html), Excel (XLSX), [LibreOffice Calc](https://www.libreoffice.org/discover/calc/) (ODS) and [Data Package](https://datahub.io/docs/data-packages/tabular). |
| [tojsonl](tojsonl.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="uses additional memory proportional to the cardinality of the columns in the CSV.">ğŸ˜£</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="requires UTF-8 encoded input.">ğŸ”£</abbr><abbr title="&quot;automagical&quot; commands that uses stats and/or frequency tables to work &quot;smarter&quot; & &quot;faster&quot;.">ğŸª„</abbr><abbr title="Limited Extended input support.">ğŸ—ƒï¸</abbr> | Smartly converts CSV to a newline-delimited JSON ([JSONL](https://jsonlines.org/)/[NDJSON](http://ndjson.org/)). By scanning the CSV first, it "smartly" infers the appropriate JSON data type for each column. See `jsonl` command to convert JSONL to CSV. |
| [transpose](transpose.md)<br><abbr title="loads entire CSV into memory, though `dedup`, `stats` & `transpose` have &quot;streaming&quot; modes as well.">ğŸ¤¯</abbr><abbr title="has powerful column selector support. See `select` for syntax.">ğŸ‘†</abbr> | Transpose rows/columns of a CSV. |
| [validate](validate.md)<br><abbr title="uses an index when available.">ğŸ“‡</abbr><abbr title="multithreaded even without an index.">ğŸš€</abbr><abbr title="has web-aware options.">ğŸŒ</abbr><abbr title="has lookup table support, enabling runtime &quot;lookups&quot; against local or remote reference CSVs.">ğŸ“š</abbr><abbr title="Extended input support.">ğŸ—„ï¸</abbr>![CKAN](../images/ckan.png "has CKAN-aware integration options.") | Validate CSV data [_blazingly-fast_](https://github.com/Stranger6667/jsonschema-rs?tab=readme-ov-file#performance "using jsonschema-rs - the fastest JSON Schema validator for Rust") using [JSON Schema Validation (Draft 2020-12)](https://json-schema.org/draft/2020-12/json-schema-validation.html) (e.g. _up to 780,031 rows/second_[^1] using [NYC's 311 schema](https://github.com/dathere/qsv/blob/master/resources/test/311_Service_Requests_from_2010_to_Present-2022-03-04.csv.schema.json) generated by the [`schema`](../../README.md#schema_deeplink) command) & put invalid records into a separate file along with a detailed validation error report. Supports several custom JSON Schema formats & keywords: * `currency` custom format with [ISO-4217](https://en.wikipedia.org/wiki/ISO_4217) validation * `dynamicEnum` custom keyword that supports enum validation against a CSV on the filesystem or a URL (http/https/ckan & dathere URL schemes supported) * `uniqueCombinedWith` custom keyword to validate uniqueness across multiple columns for composite key validation. If no JSON schema file is provided, validates if a CSV conforms to the [RFC 4180 standard](../../README.md#rfc-4180-csv-standard) and is UTF-8 encoded. |

---

### Legend

âœ¨: enabled by a [feature flag](../../README.md#feature-flags).  
ğŸ“‡: uses an index when available.  
ğŸ¤¯: loads entire CSV into memory, though `dedup`, `stats` & `transpose` have "streaming" modes as well.  
ğŸ˜£: uses additional memory proportional to the cardinality of the columns in the CSV.  
ğŸ§ : expensive operations are memoized with available inter-session Redis/Disk caching for fetch commands.  
ğŸ—„ï¸: [Extended input support](../../README.md#extended-input-support).  
ğŸ—ƒï¸: [Limited Extended input support](../../README.md#limited-extended-input-support).  
ğŸ»â€â„ï¸: command powered/accelerated by [![polars 0.53.0:ceb6366](https://img.shields.io/badge/polars-0.53.0:ceb6366-blue?logo=polars  
)](https://github.com/pola-rs/polars/releases/tag/rs-0.53.0) vectorized query engine.  
ğŸ¤–: command uses Natural Language Processing or Generative AI.  
ğŸï¸: multithreaded and/or faster when an index (ğŸ“‡) is available.  
ğŸš€: multithreaded even without an index.  
![CKAN](../images/ckan.png) : has [CKAN](https://ckan.org)-aware integration options.  
ğŸŒ: has web-aware options.  
ğŸ”£: requires UTF-8 encoded input.  
ğŸ‘†: has powerful column selector support. See [`select`](https://github.com/dathere/qsv/blob/master/src/cmd/select.rs#L2) for syntax.  
ğŸª„: "automagical" commands that uses stats and/or frequency tables to work "smarter" & "faster".  
ğŸ“š: has lookup table support, enabling runtime "lookups" against local or remote reference CSVs.  
ğŸŒ: has geospatial capabilities.  
â›©ï¸: uses [Mini Jinja](https://docs.rs/minijinja/latest/minijinja/) template engine.  
![Luau](../images/luau.png) : uses [Luau](https://luau.org/) [0.708](https://github.com/Roblox/luau/releases/tag/0.708) as an embedded scripting [DSL](https://en.wikipedia.org/wiki/Domain-specific_language).  
ğŸ–¥ï¸: part of the User Interface (UI) feature group  

---
**[README](../../README.md)**
